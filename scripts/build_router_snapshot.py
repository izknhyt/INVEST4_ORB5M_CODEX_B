#!/usr/bin/env python3
"""Assemble a router snapshot from the latest strategy run artifacts.

The command inspects strategy manifests, collects enriched ``metrics.json``
files generated by ``scripts/run_sim.py`` (or compatible runners), and emits a
snapshot layout compatible with ``scripts/report_portfolio_summary.py``:

```
<output>/
  telemetry.json
  metrics/
    <manifest_id>.json
    configs/strategies/<manifest>.yaml
```

Pairwise strategy correlations are derived from the equity curves embedded in
the metrics files. Active position counts are merged with manifest risk data
via :func:`core.router_pipeline.build_portfolio_state` so the resulting
``telemetry.json`` matches the contract used by the router pipeline.
"""

from __future__ import annotations

import argparse
import csv
import json
from dataclasses import dataclass
from datetime import datetime
from pathlib import Path
import shutil
import sys
from statistics import StatisticsError, correlation
from typing import Any, Dict, Iterable, List, Mapping, Optional, Sequence, Tuple

ROOT = Path(__file__).resolve().parents[1]
if str(ROOT) not in sys.path:
    sys.path.insert(0, str(ROOT))

from configs.strategies.loader import StrategyManifest, load_manifest
from core.router_pipeline import PortfolioTelemetry, build_portfolio_state

DEFAULT_MANIFESTS = [Path("configs/strategies")]
DEFAULT_OUTPUT = Path("runs/router_pipeline/latest")
DEFAULT_RUNS_INDEX = Path("runs/index.csv")


@dataclass
class RunArtifact:
    manifest: StrategyManifest
    run_dir: Path
    metrics_path: Path
    metrics_payload: Mapping[str, Any]


def _parse_iso_timestamp(value: str) -> datetime:
    if value.endswith("Z"):
        value = value[:-1] + "+00:00"
    return datetime.fromisoformat(value)


def _normalise_curve(raw: Sequence[Any], *, manifest_id: str, source: Path) -> List[Tuple[datetime, float]]:
    if not isinstance(raw, Sequence) or not raw:
        raise ValueError(f"metrics at {source} for {manifest_id} missing equity_curve entries")
    points: List[Tuple[datetime, float]] = []
    for entry in raw:
        if isinstance(entry, Mapping):
            ts = entry.get("ts") or entry.get("timestamp") or entry.get("date")
            equity = entry.get("equity") or entry.get("value") or entry.get("equity_value")
        elif isinstance(entry, Sequence) and len(entry) >= 2:
            ts, equity = entry[0], entry[1]
        else:
            raise ValueError(f"unsupported equity curve entry {entry!r} in {source}")
        if ts is None:
            raise ValueError(f"equity curve entry missing timestamp in {source}")
        ts_str = str(ts)
        try:
            dt = _parse_iso_timestamp(ts_str)
        except ValueError as exc:
            raise ValueError(f"invalid ISO timestamp {ts_str!r} in {source}") from exc
        try:
            value = float(equity)
        except (TypeError, ValueError) as exc:
            raise ValueError(f"non-numeric equity value {equity!r} in {source}") from exc
        points.append((dt, value))
    points.sort(key=lambda item: item[0])
    return points


def _align_series(points: List[Tuple[datetime, float]], timeline: Sequence[datetime], *, manifest_id: str, source: Path) -> List[float]:
    aligned: List[float] = []
    idx = 0
    last_value: Optional[float] = None
    for ts in timeline:
        while idx < len(points) and points[idx][0] <= ts:
            last_value = points[idx][1]
            idx += 1
        if last_value is None:
            raise ValueError(
                f"equity curve for {manifest_id} (from {source}) missing value on or before {ts.isoformat()}"
            )
        aligned.append(last_value)
    return aligned


def _compute_pairwise_correlations(
    curves: Mapping[str, List[Tuple[datetime, float]]],
    *,
    sources: Mapping[str, Path],
) -> Dict[str, Dict[str, float]]:
    if not curves:
        return {}
    timeline = sorted({point[0] for series in curves.values() for point in series})
    if len(timeline) < 2:
        return {key: {} for key in curves}
    aligned: Dict[str, List[float]] = {}
    for manifest_id, series in curves.items():
        aligned[manifest_id] = _align_series(series, timeline, manifest_id=manifest_id, source=sources[manifest_id])
    returns_map: Dict[str, List[float]] = {}
    for manifest_id, values in aligned.items():
        returns = [values[i] - values[i - 1] for i in range(1, len(values))]
        returns_map[manifest_id] = returns
    keys = sorted(curves)
    matrix: Dict[str, Dict[str, float]] = {key: {} for key in keys}
    for idx, a in enumerate(keys):
        for jdx in range(idx + 1, len(keys)):
            b = keys[jdx]
            series_a = returns_map[a]
            series_b = returns_map[b]
            if len(series_a) != len(series_b) or len(series_a) < 2:
                corr_val = 0.0
            else:
                try:
                    corr_val = correlation(series_a, series_b)
                except StatisticsError:
                    corr_val = 0.0
            matrix[a][b] = corr_val
            matrix[b][a] = corr_val
    return matrix


def _augment_tag_correlations(
    manifests: Iterable[StrategyManifest],
    pairwise: Mapping[str, Dict[str, float]],
) -> Dict[str, Dict[str, float]]:
    tag_map: Dict[str, Dict[str, float]] = {}
    for manifest in manifests:
        series = pairwise.get(manifest.id, {})
        if not series:
            continue
        for tag in manifest.router.correlation_tags:
            target = tag_map.setdefault(str(tag), {})
            for other_id, value in series.items():
                prev = target.get(other_id)
                if prev is None or abs(value) > abs(prev):
                    target[other_id] = value
    return {key: value for key, value in tag_map.items() if value}


def _load_manifests(paths: Sequence[Path]) -> Dict[str, StrategyManifest]:
    manifests: Dict[str, StrategyManifest] = {}
    for path in paths:
        if path.is_file():
            manifest = load_manifest(path)
            setattr(manifest, "_source_path", Path(path).resolve())
            manifests[manifest.id] = manifest
        elif path.is_dir():
            for manifest_path in sorted(path.rglob("*.yaml")):
                manifest = load_manifest(manifest_path)
                setattr(manifest, "_source_path", Path(manifest_path).resolve())
                manifests[manifest.id] = manifest
        else:
            raise FileNotFoundError(f"manifest path not found: {path}")
    if not manifests:
        raise ValueError("no manifests discovered from provided paths")
    return manifests


def _load_runs_index(index_path: Path) -> Dict[str, Path]:
    if not index_path.exists():
        return {}
    with index_path.open(newline="", encoding="utf-8") as handle:
        reader = csv.DictReader(handle)
        if not reader.fieldnames or "manifest_id" not in reader.fieldnames:
            return {}
        latest: Dict[str, Tuple[str, Path]] = {}
        for row in reader:
            manifest_id = row.get("manifest_id")
            run_dir = row.get("run_dir")
            timestamp = row.get("timestamp") or ""
            if not manifest_id or not run_dir:
                continue
            try:
                run_path = Path(run_dir)
                if not run_path.is_absolute():
                    run_path = (ROOT / run_path).resolve()
            except TypeError:
                continue
            current = latest.get(manifest_id)
            if current is None or timestamp > current[0]:
                latest[manifest_id] = (timestamp, run_path)
    return {key: value[1] for key, value in latest.items()}


def _parse_mapping_arg(values: Sequence[str], *, label: str) -> Dict[str, str]:
    mapping: Dict[str, str] = {}
    for raw in values:
        if "=" not in raw:
            raise ValueError(f"invalid {label} mapping '{raw}' (expected key=value)")
        key, value = raw.split("=", 1)
        key = key.strip()
        value = value.strip()
        if not key or not value:
            raise ValueError(f"invalid {label} mapping '{raw}' (empty key or value)")
        mapping[key] = value
    return mapping


def _resolve_metrics_path(raw: str) -> Path:
    path = Path(raw)
    if path.is_dir():
        candidate = path / "metrics.json"
    else:
        candidate = path
    if not candidate.exists():
        raise FileNotFoundError(f"metrics artifact not found at {candidate}")
    return candidate


def _load_run_artifacts(
    manifests: Mapping[str, StrategyManifest],
    runs_by_manifest: Mapping[str, str],
) -> Dict[str, RunArtifact]:
    artifacts: Dict[str, RunArtifact] = {}
    for manifest_id, manifest in manifests.items():
        run_entry = runs_by_manifest.get(manifest_id)
        if not run_entry:
            raise ValueError(f"no run directory provided for manifest {manifest_id}")
        metrics_path = _resolve_metrics_path(run_entry)
        run_dir = metrics_path.parent
        payload = json.loads(metrics_path.read_text(encoding="utf-8"))
        artifacts[manifest_id] = RunArtifact(
            manifest=manifest,
            run_dir=run_dir,
            metrics_path=metrics_path,
            metrics_payload=payload,
        )
    return artifacts


def _relative_manifest_path(manifest_path: Path) -> Path:
    try:
        return manifest_path.relative_to(ROOT)
    except ValueError:
        return manifest_path.name


def _manifest_source_path(manifest: StrategyManifest) -> Path:
    source = getattr(manifest, "_source_path", None)
    if source is not None:
        return Path(source)
    candidate = ROOT / "configs" / "strategies" / f"{manifest.id}.yaml"
    if candidate.exists():
        return candidate
    raise FileNotFoundError(f"unable to resolve manifest path for {manifest.id}")


def _prepare_manifests_for_output(
    artifacts: Mapping[str, RunArtifact],
    metrics_dir: Path,
) -> Dict[str, Path]:
    manifest_paths: Dict[str, Path] = {}
    for manifest_id, artifact in artifacts.items():
        manifest_path = _manifest_source_path(artifact.manifest)
        rel_path = _relative_manifest_path(manifest_path)
        target = metrics_dir / rel_path
        target.parent.mkdir(parents=True, exist_ok=True)
        shutil.copy2(manifest_path, target)
        manifest_paths[manifest_id] = rel_path
    return manifest_paths


def _build_runtime_metrics(payload: Mapping[str, Any]) -> Optional[Mapping[str, Any]]:
    runtime = payload.get("runtime")
    if not isinstance(runtime, Mapping):
        return None
    health = runtime.get("execution_health")
    if not isinstance(health, Mapping):
        return None
    return {"execution_health": dict(health)}


def _parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(description=__doc__)
    parser.add_argument(
        "--manifest",
        dest="manifests",
        action="append",
        type=Path,
        help="Strategy manifest file or directory (defaults to configs/strategies)",
    )
    parser.add_argument(
        "--manifest-run",
        dest="manifest_runs",
        action="append",
        default=[],
        help="Mapping of manifest id to run directory or metrics.json (format id=path)",
    )
    parser.add_argument(
        "--runs-index",
        type=Path,
        default=DEFAULT_RUNS_INDEX,
        help="runs/index.csv path used to infer latest runs when available",
    )
    parser.add_argument(
        "--positions",
        action="append",
        default=[],
        help="Active position overrides per manifest (format id=count)",
    )
    parser.add_argument(
        "--output",
        type=Path,
        default=DEFAULT_OUTPUT,
        help="Directory that will receive telemetry.json and metrics/*.json",
    )
    parser.add_argument(
        "--indent",
        type=int,
        default=2,
        help="Indent level for generated JSON (use 0 for compact output)",
    )
    return parser.parse_args()


def main() -> int:
    args = _parse_args()
    manifest_paths = args.manifests or DEFAULT_MANIFESTS
    manifests = _load_manifests(manifest_paths)

    runs_mapping = _load_runs_index(args.runs_index)
    explicit_runs = _parse_mapping_arg(args.manifest_runs, label="manifest run") if args.manifest_runs else {}
    runs_mapping.update(explicit_runs)

    artifacts = _load_run_artifacts(manifests, runs_mapping)

    curves: Dict[str, List[Tuple[datetime, float]]] = {}
    sources: Dict[str, Path] = {}
    runtime_metrics: Dict[str, Mapping[str, Any]] = {}
    metrics_payloads: Dict[str, Mapping[str, Any]] = {}
    for manifest_id, artifact in artifacts.items():
        payload = artifact.metrics_payload
        metrics_payloads[manifest_id] = payload
        curve = payload.get("equity_curve")
        curves[manifest_id] = _normalise_curve(
            curve,
            manifest_id=manifest_id,
            source=artifact.metrics_path,
        )
        sources[manifest_id] = artifact.metrics_path
        runtime_entry = _build_runtime_metrics(payload)
        if runtime_entry:
            runtime_metrics[manifest_id] = runtime_entry

    pairwise = _compute_pairwise_correlations(curves, sources=sources)
    tag_correlations = _augment_tag_correlations(manifests.values(), pairwise)
    strategy_correlations: Dict[str, Dict[str, float]] = {**pairwise, **tag_correlations}

    position_overrides = _parse_mapping_arg(args.positions, label="positions") if args.positions else {}
    active_positions: Dict[str, int] = {}
    for manifest_id in manifests:
        raw_value = position_overrides.get(manifest_id, "0")
        try:
            active_positions[manifest_id] = int(raw_value)
        except ValueError as exc:
            raise ValueError(f"invalid active position count '{raw_value}' for {manifest_id}") from exc

    telemetry_seed = PortfolioTelemetry(
        active_positions=active_positions,
        strategy_correlations=strategy_correlations,
    )
    portfolio_state = build_portfolio_state(
        manifests.values(),
        telemetry=telemetry_seed,
        runtime_metrics=runtime_metrics or None,
    )

    output_dir = args.output
    metrics_dir = output_dir / "metrics"
    metrics_dir.mkdir(parents=True, exist_ok=True)
    manifest_rel_paths = _prepare_manifests_for_output(artifacts, metrics_dir)

    indent = None if args.indent <= 0 else args.indent

    telemetry_payload = {
        "active_positions": portfolio_state.active_positions,
        "category_utilisation_pct": portfolio_state.category_utilisation_pct,
        "category_caps_pct": portfolio_state.category_caps_pct,
        "gross_exposure_pct": portfolio_state.gross_exposure_pct,
        "gross_exposure_cap_pct": portfolio_state.gross_exposure_cap_pct,
        "strategy_correlations": portfolio_state.strategy_correlations,
        "execution_health": portfolio_state.execution_health,
    }

    telemetry_path = output_dir / "telemetry.json"
    telemetry_path.parent.mkdir(parents=True, exist_ok=True)
    with telemetry_path.open("w", encoding="utf-8") as handle:
        json.dump(telemetry_payload, handle, indent=indent, sort_keys=True)
        handle.write("\n")

    for manifest_id, artifact in artifacts.items():
        manifest_rel = manifest_rel_paths[manifest_id]
        payload = metrics_payloads[manifest_id]
        out_payload: Dict[str, Any] = {
            "manifest_id": manifest_id,
            "manifest_path": str(manifest_rel),
            "run_dir": str(artifact.run_dir),
            "source_metrics": str(artifact.metrics_path),
            "equity_curve": payload.get("equity_curve"),
        }
        runtime_entry = _build_runtime_metrics(payload)
        if runtime_entry:
            out_payload["runtime"] = runtime_entry
        out_path = metrics_dir / f"{manifest_id}.json"
        with out_path.open("w", encoding="utf-8") as handle:
            json.dump(out_payload, handle, indent=indent, sort_keys=True)
            handle.write("\n")

    print(f"router snapshot written to {output_dir}")
    return 0


if __name__ == "__main__":  # pragma: no cover
    raise SystemExit(main())
